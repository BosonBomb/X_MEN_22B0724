{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/TachibanaYoshino/AnimeGANv3.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpSUVdQuSdyz",
        "outputId": "99aba903-b4e1-41db-ccbf-066068874bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AnimeGANv3'...\n",
            "remote: Enumerating objects: 531, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 531 (delta 54), reused 29 (delta 24), pack-reused 461 (from 1)\u001b[K\n",
            "Receiving objects: 100% (531/531), 359.63 MiB | 15.48 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n",
            "Updating files: 100% (216/216), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh9gkBGo2nUT"
      },
      "source": [
        "Interactive Demo for AnimeGANv2:FacePortraitv2 created by @xhlulu\n",
        "\n",
        "Learn more about the model here: https://github.com/bryandlee/animegan2-pytorch\n",
        "\n",
        "To start using this, run the cells with `Ctrl+F9` or \"Runtime > Run All\"\n",
        "\n",
        "For accelerated inference, you can use a GPU. Simply select \"Runtime > Change runtime type\" and select \"GPU\" in the \"Hardware Acceleration\" dropdown.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/AnimeGANv3 && cd tools && python edge_smooth.py --dataset Hayao --img_size 256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1ns5p7ES_R1",
        "outputId": "18dcc058-e259-4f9d-f6ec-48cfdce4bb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/AnimeGANv3/tools/edge_smooth.py\", line 2, in <module>\n",
            "    from tools.utils import check_folder\n",
            "ModuleNotFoundError: No module named 'tools'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gQWWtQJTU4b",
        "outputId": "ce051a99-debd-45b4-9e4e-609c0c848036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AnimeGANv3  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1' -O /content/AnimeGANv3_Hayao_STYLE_36.onnx\n"
      ],
      "metadata": {
        "id": "ERgWUIOrR5-t",
        "outputId": "72c713c4-d097-4c05-b55a-6c59d4dadca3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-03 12:34:16--  https://docs.google.com/uc?export=download&id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.79.113, 173.194.79.100, 173.194.79.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.79.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1&export=download [following]\n",
            "--2024-11-03 12:34:17--  https://drive.usercontent.google.com/download?id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.69.132, 2a00:1450:4013:c04::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.69.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4232991 (4.0M) [application/octet-stream]\n",
            "Saving to: ‘/content/AnimeGANv3_Hayao_STYLE_36.onnx’\n",
            "\n",
            "/content/AnimeGANv3 100%[===================>]   4.04M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-11-03 12:34:20 (161 MB/s) - ‘/content/AnimeGANv3_Hayao_STYLE_36.onnx’ saved [4232991/4232991]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "id": "ToS1u3xURf5K",
        "outputId": "08b34daf-9d12-4d57-874b-d654b31d83ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import ipywidgets as widgets\n",
        "import IPython.display as display\n",
        "from google.colab import files\n",
        "import os\n",
        "import onnxruntime as ort\n",
        "import time\n",
        "\n",
        "# Load the AnimeGANv3 model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = 'AnimeGANv3_Hayao_STYLE_36'  # Model name\n",
        "session = ort.InferenceSession(f'/content/{model}.onnx', providers=['CUDAExecutionProvider' if device == 'cuda' else 'CPUExecutionProvider'])\n",
        "\n",
        "# Load the face2paint model\n",
        "face2paint_model = torch.hub.load(\"bryandlee/animegan2-pytorch:main\", \"generator\", device=device).eval()\n",
        "face2paint = torch.hub.load(\"bryandlee/animegan2-pytorch:main\", \"face2paint\", device=device)\n",
        "\n",
        "# Function to preprocess image for AnimeGANv3\n",
        "def process_image(img):\n",
        "    img = cv2.resize(img, (512, 512))  # Resize image to expected size\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 127.5 - 1.0\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "    return img\n",
        "\n",
        "# Function to convert non-face areas using AnimeGANv3\n",
        "def convert_non_face(img, original_shape):\n",
        "    x = session.get_inputs()[0].name\n",
        "    y = session.get_outputs()[0].name\n",
        "\n",
        "    fake_img = session.run(None, {x: img})[0]\n",
        "\n",
        "    # Postprocess output image\n",
        "    images = (np.squeeze(fake_img) + 1.) / 2 * 255\n",
        "    images = np.clip(images, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Resize to original shape\n",
        "    output_image = cv2.resize(images, (original_shape[1], original_shape[0]))  # Resize back to original\n",
        "    return cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Function to extract face using OpenCV's Haar Cascade\n",
        "def extract_face(image):\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    img_array = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)  # Convert to BGR for OpenCV\n",
        "    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face = img_array[y:y+h, x:x+w]\n",
        "        return face, (x, y, w, h)  # Return the cropped face and its location\n",
        "    return None, None  # Return None if no face is detected\n",
        "\n",
        "# Function to process video\n",
        "def process_video(input_video_path):\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    output_video_path = \"output_video.mp4\"\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, 30.0, (frame_width, frame_height))\n",
        "\n",
        "    start_time = time.time()  # Start timer\n",
        "\n",
        "    for frame_number in range(total_frames):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Extract face from the frame\n",
        "        face, coords = extract_face(frame)\n",
        "\n",
        "        # If a face is detected\n",
        "        if face is not None:\n",
        "            # Transform face using face2paint\n",
        "            face_pil = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
        "            im_out = face2paint(face2paint_model, face_pil, side_by_side=False)\n",
        "\n",
        "            # Convert the output to a NumPy array\n",
        "            im_out_np = np.array(im_out)\n",
        "\n",
        "            # Resize the transformed face to match the detected face's dimensions\n",
        "            resized_face = cv2.resize(im_out_np, (coords[2], coords[3]))  # Resize to (width, height)\n",
        "\n",
        "            # Replace the original face in the frame with the transformed face\n",
        "            frame[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]] = cv2.cvtColor(resized_face, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            # Transform non-face areas using AnimeGANv3\n",
        "            full_transformed_img = convert_non_face(process_image(frame), frame.shape)  # Keep original shape\n",
        "\n",
        "            # Create a mask and combine images\n",
        "            mask = np.ones(frame.shape[:2], dtype=np.uint8) * 255\n",
        "            mask[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]] = 0\n",
        "            frame[mask == 255] = full_transformed_img[mask == 255]\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "        # Calculate elapsed time and estimate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        remaining_time = (elapsed_time / (frame_number + 1)) * (total_frames - (frame_number + 1))\n",
        "        print(f\"Processed frame {frame_number + 1}/{total_frames}. Estimated time remaining: {remaining_time:.2f} seconds.\")\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    return output_video_path\n",
        "\n",
        "# User interface\n",
        "button = widgets.Button(description=\"Upload Video to Transform\")\n",
        "output = widgets.Output()\n",
        "\n",
        "def run(b):\n",
        "    button.disabled = True\n",
        "\n",
        "    with output:\n",
        "        display.clear_output()\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for fname in uploaded:\n",
        "        input_video_path = fname\n",
        "        output_video_path = process_video(input_video_path)\n",
        "        print(f\"Transformed video saved at: {output_video_path}\")\n",
        "\n",
        "    button.disabled = False\n",
        "\n",
        "button.on_click(run)\n",
        "display.display(button, output)\n"
      ],
      "metadata": {
        "id": "k26kKWXeRKmV",
        "outputId": "2bbc5ddc-3ad4-4457-b805-baff2bf5ac96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c11bd29632ee4282bcfde719c6ed4d37",
            "3f2acbcc67354bc79bae93ae6e5d7a38",
            "45d9526b78c24d62988518aa5c571cf3",
            "8e31dccc22a6446cb2eb73327de18226",
            "7cc3a88186444cb984cbb2ebbad5ceac"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/bryandlee_animegan2-pytorch_main\n",
            "Using cache found in /root/.cache/torch/hub/bryandlee_animegan2-pytorch_main\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Upload Video to Transform', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c11bd29632ee4282bcfde719c6ed4d37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e31dccc22a6446cb2eb73327de18226"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8bb9150e-6623-4267-9072-2f156c3487cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8bb9150e-6623-4267-9072-2f156c3487cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Video2_AnimeGANv3.mp4 to Video2_AnimeGANv3 (3).mp4\n",
            "Processed frame 1/565. Estimated time remaining: 5321.22 seconds.\n",
            "Processed frame 2/565. Estimated time remaining: 4914.35 seconds.\n",
            "Processed frame 3/565. Estimated time remaining: 4982.97 seconds.\n",
            "Processed frame 4/565. Estimated time remaining: 4873.49 seconds.\n",
            "Processed frame 5/565. Estimated time remaining: 4823.89 seconds.\n",
            "Processed frame 6/565. Estimated time remaining: 4837.31 seconds.\n",
            "Processed frame 7/565. Estimated time remaining: 4742.57 seconds.\n",
            "Processed frame 8/565. Estimated time remaining: 4764.40 seconds.\n",
            "Processed frame 9/565. Estimated time remaining: 4759.49 seconds.\n",
            "Processed frame 10/565. Estimated time remaining: 4706.42 seconds.\n",
            "Processed frame 11/565. Estimated time remaining: 4723.24 seconds.\n",
            "Processed frame 12/565. Estimated time remaining: 4683.55 seconds.\n",
            "Processed frame 13/565. Estimated time remaining: 4679.39 seconds.\n",
            "Processed frame 14/565. Estimated time remaining: 4688.09 seconds.\n",
            "Processed frame 15/565. Estimated time remaining: 4651.54 seconds.\n",
            "Processed frame 16/565. Estimated time remaining: 4658.95 seconds.\n",
            "Processed frame 17/565. Estimated time remaining: 4651.51 seconds.\n",
            "Processed frame 18/565. Estimated time remaining: 4627.43 seconds.\n",
            "Processed frame 19/565. Estimated time remaining: 4634.74 seconds.\n",
            "Processed frame 20/565. Estimated time remaining: 4605.58 seconds.\n",
            "Processed frame 21/565. Estimated time remaining: 4604.71 seconds.\n",
            "Processed frame 22/565. Estimated time remaining: 4607.54 seconds.\n",
            "Processed frame 23/565. Estimated time remaining: 4580.01 seconds.\n",
            "Processed frame 24/565. Estimated time remaining: 4582.67 seconds.\n",
            "Processed frame 25/565. Estimated time remaining: 4570.34 seconds.\n",
            "Processed frame 26/565. Estimated time remaining: 4556.38 seconds.\n",
            "Processed frame 27/565. Estimated time remaining: 4557.37 seconds.\n",
            "Processed frame 28/565. Estimated time remaining: 4533.20 seconds.\n",
            "Processed frame 29/565. Estimated time remaining: 4534.22 seconds.\n",
            "Processed frame 30/565. Estimated time remaining: 4534.10 seconds.\n",
            "Processed frame 31/565. Estimated time remaining: 4512.10 seconds.\n",
            "Processed frame 32/565. Estimated time remaining: 4512.54 seconds.\n",
            "Processed frame 33/565. Estimated time remaining: 4502.09 seconds.\n",
            "Processed frame 34/565. Estimated time remaining: 4488.26 seconds.\n",
            "Processed frame 35/565. Estimated time remaining: 4486.95 seconds.\n",
            "Processed frame 36/565. Estimated time remaining: 4466.81 seconds.\n",
            "Processed frame 37/565. Estimated time remaining: 4465.80 seconds.\n",
            "Processed frame 38/565. Estimated time remaining: 4463.06 seconds.\n",
            "Processed frame 39/565. Estimated time remaining: 4444.29 seconds.\n",
            "Processed frame 40/565. Estimated time remaining: 4450.73 seconds.\n",
            "Processed frame 41/565. Estimated time remaining: 4442.28 seconds.\n",
            "Processed frame 42/565. Estimated time remaining: 4428.00 seconds.\n",
            "Processed frame 43/565. Estimated time remaining: 4425.82 seconds.\n",
            "Processed frame 44/565. Estimated time remaining: 4409.05 seconds.\n",
            "Processed frame 45/565. Estimated time remaining: 4404.06 seconds.\n",
            "Processed frame 46/565. Estimated time remaining: 4400.47 seconds.\n",
            "Processed frame 47/565. Estimated time remaining: 4383.64 seconds.\n",
            "Processed frame 48/565. Estimated time remaining: 4379.35 seconds.\n",
            "Processed frame 49/565. Estimated time remaining: 4371.28 seconds.\n",
            "Processed frame 50/565. Estimated time remaining: 4356.89 seconds.\n",
            "Processed frame 51/565. Estimated time remaining: 4354.01 seconds.\n",
            "Processed frame 52/565. Estimated time remaining: 4339.18 seconds.\n",
            "Processed frame 53/565. Estimated time remaining: 4332.94 seconds.\n",
            "Processed frame 54/565. Estimated time remaining: 4329.73 seconds.\n",
            "Processed frame 55/565. Estimated time remaining: 4314.19 seconds.\n",
            "Processed frame 56/565. Estimated time remaining: 4310.45 seconds.\n",
            "Processed frame 57/565. Estimated time remaining: 4302.69 seconds.\n",
            "Processed frame 58/565. Estimated time remaining: 4290.42 seconds.\n",
            "Processed frame 59/565. Estimated time remaining: 4286.33 seconds.\n",
            "Processed frame 60/565. Estimated time remaining: 4208.48 seconds.\n",
            "Processed frame 61/565. Estimated time remaining: 4196.50 seconds.\n",
            "Processed frame 62/565. Estimated time remaining: 4123.84 seconds.\n",
            "Processed frame 63/565. Estimated time remaining: 4053.23 seconds.\n",
            "Processed frame 64/565. Estimated time remaining: 3985.15 seconds.\n",
            "Processed frame 65/565. Estimated time remaining: 3918.90 seconds.\n",
            "Processed frame 66/565. Estimated time remaining: 3854.60 seconds.\n",
            "Processed frame 67/565. Estimated time remaining: 3850.05 seconds.\n",
            "Processed frame 68/565. Estimated time remaining: 3787.60 seconds.\n",
            "Processed frame 69/565. Estimated time remaining: 3726.92 seconds.\n",
            "Processed frame 70/565. Estimated time remaining: 3730.31 seconds.\n",
            "Processed frame 71/565. Estimated time remaining: 3672.06 seconds.\n",
            "Processed frame 72/565. Estimated time remaining: 3615.42 seconds.\n",
            "Processed frame 73/565. Estimated time remaining: 3560.37 seconds.\n",
            "Processed frame 74/565. Estimated time remaining: 3561.20 seconds.\n",
            "Processed frame 75/565. Estimated time remaining: 3508.99 seconds.\n",
            "Processed frame 76/565. Estimated time remaining: 3507.92 seconds.\n",
            "Processed frame 77/565. Estimated time remaining: 3512.86 seconds.\n",
            "Processed frame 78/565. Estimated time remaining: 3462.36 seconds.\n",
            "Processed frame 79/565. Estimated time remaining: 3412.97 seconds.\n",
            "Processed frame 80/565. Estimated time remaining: 3412.80 seconds.\n",
            "Processed frame 81/565. Estimated time remaining: 3366.28 seconds.\n",
            "Processed frame 82/565. Estimated time remaining: 3320.81 seconds.\n",
            "Processed frame 83/565. Estimated time remaining: 3321.46 seconds.\n",
            "Processed frame 84/565. Estimated time remaining: 3327.07 seconds.\n",
            "Processed frame 85/565. Estimated time remaining: 3282.49 seconds.\n",
            "Processed frame 86/565. Estimated time remaining: 3238.91 seconds.\n",
            "Processed frame 87/565. Estimated time remaining: 3196.30 seconds.\n",
            "Processed frame 88/565. Estimated time remaining: 3154.67 seconds.\n",
            "Processed frame 89/565. Estimated time remaining: 3156.57 seconds.\n",
            "Processed frame 90/565. Estimated time remaining: 3159.35 seconds.\n",
            "Processed frame 91/565. Estimated time remaining: 3119.30 seconds.\n",
            "Processed frame 92/565. Estimated time remaining: 3080.20 seconds.\n",
            "Processed frame 93/565. Estimated time remaining: 3041.88 seconds.\n",
            "Processed frame 94/565. Estimated time remaining: 3004.37 seconds.\n",
            "Processed frame 95/565. Estimated time remaining: 3011.46 seconds.\n",
            "Processed frame 96/565. Estimated time remaining: 3012.93 seconds.\n",
            "Processed frame 97/565. Estimated time remaining: 2977.34 seconds.\n",
            "Processed frame 98/565. Estimated time remaining: 2942.71 seconds.\n",
            "Processed frame 99/565. Estimated time remaining: 2908.60 seconds.\n",
            "Processed frame 100/565. Estimated time remaining: 2875.10 seconds.\n",
            "Processed frame 101/565. Estimated time remaining: 2842.29 seconds.\n",
            "Processed frame 102/565. Estimated time remaining: 2810.49 seconds.\n",
            "Processed frame 103/565. Estimated time remaining: 2778.65 seconds.\n",
            "Processed frame 104/565. Estimated time remaining: 2747.09 seconds.\n",
            "Processed frame 105/565. Estimated time remaining: 2716.13 seconds.\n",
            "Processed frame 106/565. Estimated time remaining: 2685.81 seconds.\n",
            "Processed frame 107/565. Estimated time remaining: 2655.97 seconds.\n",
            "Processed frame 108/565. Estimated time remaining: 2626.70 seconds.\n",
            "Processed frame 109/565. Estimated time remaining: 2597.95 seconds.\n",
            "Processed frame 110/565. Estimated time remaining: 2600.91 seconds.\n",
            "Processed frame 111/565. Estimated time remaining: 2608.78 seconds.\n",
            "Processed frame 112/565. Estimated time remaining: 2615.90 seconds.\n",
            "Processed frame 113/565. Estimated time remaining: 2588.02 seconds.\n",
            "Processed frame 114/565. Estimated time remaining: 2590.44 seconds.\n",
            "Processed frame 115/565. Estimated time remaining: 2563.19 seconds.\n",
            "Processed frame 116/565. Estimated time remaining: 2536.42 seconds.\n",
            "Processed frame 117/565. Estimated time remaining: 2510.13 seconds.\n",
            "Processed frame 118/565. Estimated time remaining: 2517.49 seconds.\n",
            "Processed frame 119/565. Estimated time remaining: 2491.73 seconds.\n",
            "Processed frame 120/565. Estimated time remaining: 2498.61 seconds.\n",
            "Processed frame 121/565. Estimated time remaining: 2500.85 seconds.\n",
            "Processed frame 122/565. Estimated time remaining: 2507.51 seconds.\n",
            "Processed frame 123/565. Estimated time remaining: 2511.63 seconds.\n",
            "Processed frame 124/565. Estimated time remaining: 2515.34 seconds.\n",
            "Processed frame 125/565. Estimated time remaining: 2490.49 seconds.\n",
            "Processed frame 126/565. Estimated time remaining: 2465.96 seconds.\n",
            "Processed frame 127/565. Estimated time remaining: 2472.17 seconds.\n",
            "Processed frame 128/565. Estimated time remaining: 2448.10 seconds.\n",
            "Processed frame 129/565. Estimated time remaining: 2450.89 seconds.\n",
            "Processed frame 130/565. Estimated time remaining: 2427.95 seconds.\n",
            "Processed frame 131/565. Estimated time remaining: 2405.14 seconds.\n",
            "Processed frame 132/565. Estimated time remaining: 2382.70 seconds.\n",
            "Processed frame 133/565. Estimated time remaining: 2360.53 seconds.\n",
            "Processed frame 134/565. Estimated time remaining: 2338.64 seconds.\n",
            "Processed frame 135/565. Estimated time remaining: 2317.15 seconds.\n",
            "Processed frame 136/565. Estimated time remaining: 2295.57 seconds.\n",
            "Processed frame 137/565. Estimated time remaining: 2274.24 seconds.\n",
            "Processed frame 138/565. Estimated time remaining: 2253.22 seconds.\n",
            "Processed frame 139/565. Estimated time remaining: 2232.59 seconds.\n",
            "Processed frame 140/565. Estimated time remaining: 2212.14 seconds.\n",
            "Processed frame 141/565. Estimated time remaining: 2214.28 seconds.\n",
            "Processed frame 142/565. Estimated time remaining: 2220.19 seconds.\n",
            "Processed frame 143/565. Estimated time remaining: 2200.10 seconds.\n",
            "Processed frame 144/565. Estimated time remaining: 2205.06 seconds.\n",
            "Processed frame 145/565. Estimated time remaining: 2207.53 seconds.\n",
            "Processed frame 146/565. Estimated time remaining: 2213.17 seconds.\n",
            "Processed frame 147/565. Estimated time remaining: 2215.53 seconds.\n",
            "Processed frame 148/565. Estimated time remaining: 2219.57 seconds.\n",
            "Processed frame 149/565. Estimated time remaining: 2224.62 seconds.\n",
            "Processed frame 150/565. Estimated time remaining: 2225.91 seconds.\n",
            "Processed frame 151/565. Estimated time remaining: 2230.60 seconds.\n",
            "Processed frame 152/565. Estimated time remaining: 2211.20 seconds.\n",
            "Processed frame 153/565. Estimated time remaining: 2192.02 seconds.\n",
            "Processed frame 154/565. Estimated time remaining: 2173.09 seconds.\n",
            "Processed frame 155/565. Estimated time remaining: 2154.40 seconds.\n",
            "Processed frame 156/565. Estimated time remaining: 2135.97 seconds.\n",
            "Processed frame 157/565. Estimated time remaining: 2140.54 seconds.\n",
            "Processed frame 158/565. Estimated time remaining: 2122.35 seconds.\n",
            "Processed frame 159/565. Estimated time remaining: 2123.60 seconds.\n",
            "Processed frame 160/565. Estimated time remaining: 2127.88 seconds.\n",
            "Processed frame 161/565. Estimated time remaining: 2132.86 seconds.\n",
            "Processed frame 162/565. Estimated time remaining: 2133.71 seconds.\n",
            "Processed frame 163/565. Estimated time remaining: 2137.80 seconds.\n",
            "Processed frame 164/565. Estimated time remaining: 2139.82 seconds.\n",
            "Processed frame 165/565. Estimated time remaining: 2141.79 seconds.\n",
            "Processed frame 166/565. Estimated time remaining: 2145.24 seconds.\n",
            "Processed frame 167/565. Estimated time remaining: 2145.50 seconds.\n",
            "Processed frame 168/565. Estimated time remaining: 2148.64 seconds.\n",
            "Processed frame 169/565. Estimated time remaining: 2151.62 seconds.\n",
            "Processed frame 170/565. Estimated time remaining: 2151.44 seconds.\n",
            "Processed frame 171/565. Estimated time remaining: 2133.96 seconds.\n",
            "Processed frame 172/565. Estimated time remaining: 2116.66 seconds.\n",
            "Processed frame 173/565. Estimated time remaining: 2099.57 seconds.\n",
            "Processed frame 174/565. Estimated time remaining: 2082.65 seconds.\n",
            "Processed frame 175/565. Estimated time remaining: 2065.93 seconds.\n",
            "Processed frame 176/565. Estimated time remaining: 2049.45 seconds.\n",
            "Processed frame 177/565. Estimated time remaining: 2052.40 seconds.\n",
            "Processed frame 178/565. Estimated time remaining: 2036.09 seconds.\n",
            "Processed frame 179/565. Estimated time remaining: 2038.89 seconds.\n",
            "Processed frame 180/565. Estimated time remaining: 2038.82 seconds.\n",
            "Processed frame 181/565. Estimated time remaining: 2022.75 seconds.\n",
            "Processed frame 182/565. Estimated time remaining: 2025.24 seconds.\n",
            "Processed frame 183/565. Estimated time remaining: 2009.40 seconds.\n",
            "Processed frame 184/565. Estimated time remaining: 1993.69 seconds.\n",
            "Processed frame 185/565. Estimated time remaining: 1978.14 seconds.\n",
            "Processed frame 186/565. Estimated time remaining: 1980.54 seconds.\n",
            "Processed frame 187/565. Estimated time remaining: 1980.37 seconds.\n",
            "Processed frame 188/565. Estimated time remaining: 1982.90 seconds.\n",
            "Processed frame 189/565. Estimated time remaining: 1967.60 seconds.\n",
            "Processed frame 190/565. Estimated time remaining: 1968.71 seconds.\n",
            "Processed frame 191/565. Estimated time remaining: 1969.27 seconds.\n",
            "Processed frame 192/565. Estimated time remaining: 1954.20 seconds.\n",
            "Processed frame 193/565. Estimated time remaining: 1939.27 seconds.\n",
            "Processed frame 194/565. Estimated time remaining: 1924.51 seconds.\n",
            "Processed frame 195/565. Estimated time remaining: 1909.88 seconds.\n",
            "Processed frame 196/565. Estimated time remaining: 1895.41 seconds.\n",
            "Processed frame 197/565. Estimated time remaining: 1881.09 seconds.\n",
            "Processed frame 198/565. Estimated time remaining: 1883.33 seconds.\n",
            "Processed frame 199/565. Estimated time remaining: 1869.19 seconds.\n",
            "Processed frame 200/565. Estimated time remaining: 1855.18 seconds.\n",
            "Processed frame 201/565. Estimated time remaining: 1841.33 seconds.\n",
            "Processed frame 202/565. Estimated time remaining: 1827.60 seconds.\n",
            "Processed frame 203/565. Estimated time remaining: 1814.01 seconds.\n",
            "Processed frame 204/565. Estimated time remaining: 1800.53 seconds.\n",
            "Processed frame 205/565. Estimated time remaining: 1787.20 seconds.\n",
            "Processed frame 206/565. Estimated time remaining: 1773.98 seconds.\n",
            "Processed frame 207/565. Estimated time remaining: 1760.89 seconds.\n",
            "Processed frame 208/565. Estimated time remaining: 1747.93 seconds.\n",
            "Processed frame 209/565. Estimated time remaining: 1750.06 seconds.\n",
            "Processed frame 210/565. Estimated time remaining: 1737.21 seconds.\n",
            "Processed frame 211/565. Estimated time remaining: 1724.48 seconds.\n",
            "Processed frame 212/565. Estimated time remaining: 1724.47 seconds.\n",
            "Processed frame 213/565. Estimated time remaining: 1726.41 seconds.\n",
            "Processed frame 214/565. Estimated time remaining: 1728.19 seconds.\n",
            "Processed frame 215/565. Estimated time remaining: 1727.89 seconds.\n",
            "Processed frame 216/565. Estimated time remaining: 1729.50 seconds.\n",
            "Processed frame 217/565. Estimated time remaining: 1730.18 seconds.\n",
            "Processed frame 218/565. Estimated time remaining: 1730.25 seconds.\n",
            "Processed frame 219/565. Estimated time remaining: 1731.68 seconds.\n",
            "Processed frame 220/565. Estimated time remaining: 1731.27 seconds.\n",
            "Processed frame 221/565. Estimated time remaining: 1732.08 seconds.\n",
            "Processed frame 222/565. Estimated time remaining: 1733.30 seconds.\n",
            "Processed frame 223/565. Estimated time remaining: 1732.39 seconds.\n",
            "Processed frame 224/565. Estimated time remaining: 1733.15 seconds.\n",
            "Processed frame 225/565. Estimated time remaining: 1733.51 seconds.\n",
            "Processed frame 226/565. Estimated time remaining: 1732.70 seconds.\n",
            "Processed frame 227/565. Estimated time remaining: 1733.45 seconds.\n",
            "Processed frame 228/565. Estimated time remaining: 1732.65 seconds.\n",
            "Processed frame 229/565. Estimated time remaining: 1732.54 seconds.\n",
            "Processed frame 230/565. Estimated time remaining: 1732.97 seconds.\n",
            "Processed frame 231/565. Estimated time remaining: 1731.35 seconds.\n",
            "Processed frame 232/565. Estimated time remaining: 1731.67 seconds.\n",
            "Processed frame 233/565. Estimated time remaining: 1731.76 seconds.\n",
            "Processed frame 234/565. Estimated time remaining: 1730.11 seconds.\n",
            "Processed frame 235/565. Estimated time remaining: 1730.22 seconds.\n",
            "Processed frame 236/565. Estimated time remaining: 1729.11 seconds.\n",
            "Processed frame 237/565. Estimated time remaining: 1717.00 seconds.\n",
            "Processed frame 238/565. Estimated time remaining: 1704.93 seconds.\n",
            "Processed frame 239/565. Estimated time remaining: 1692.96 seconds.\n",
            "Processed frame 240/565. Estimated time remaining: 1681.08 seconds.\n",
            "Processed frame 241/565. Estimated time remaining: 1669.37 seconds.\n",
            "Processed frame 242/565. Estimated time remaining: 1657.74 seconds.\n",
            "Processed frame 243/565. Estimated time remaining: 1646.13 seconds.\n",
            "Processed frame 244/565. Estimated time remaining: 1634.61 seconds.\n",
            "Processed frame 245/565. Estimated time remaining: 1623.08 seconds.\n",
            "Processed frame 246/565. Estimated time remaining: 1611.65 seconds.\n",
            "Processed frame 247/565. Estimated time remaining: 1600.32 seconds.\n",
            "Processed frame 248/565. Estimated time remaining: 1589.08 seconds.\n",
            "Processed frame 249/565. Estimated time remaining: 1577.91 seconds.\n",
            "Processed frame 250/565. Estimated time remaining: 1566.85 seconds.\n",
            "Processed frame 251/565. Estimated time remaining: 1555.86 seconds.\n",
            "Processed frame 252/565. Estimated time remaining: 1554.27 seconds.\n",
            "Processed frame 253/565. Estimated time remaining: 1543.39 seconds.\n",
            "Processed frame 254/565. Estimated time remaining: 1543.31 seconds.\n",
            "Processed frame 255/565. Estimated time remaining: 1542.76 seconds.\n",
            "Processed frame 256/565. Estimated time remaining: 1541.41 seconds.\n",
            "Processed frame 257/565. Estimated time remaining: 1541.27 seconds.\n",
            "Processed frame 258/565. Estimated time remaining: 1539.72 seconds.\n",
            "Processed frame 259/565. Estimated time remaining: 1529.25 seconds.\n",
            "Processed frame 260/565. Estimated time remaining: 1518.77 seconds.\n",
            "Processed frame 261/565. Estimated time remaining: 1508.46 seconds.\n",
            "Processed frame 262/565. Estimated time remaining: 1498.21 seconds.\n",
            "Processed frame 263/565. Estimated time remaining: 1497.10 seconds.\n",
            "Processed frame 264/565. Estimated time remaining: 1496.81 seconds.\n",
            "Processed frame 265/565. Estimated time remaining: 1495.07 seconds.\n",
            "Processed frame 266/565. Estimated time remaining: 1494.62 seconds.\n",
            "Processed frame 267/565. Estimated time remaining: 1494.16 seconds.\n",
            "Processed frame 268/565. Estimated time remaining: 1492.22 seconds.\n",
            "Processed frame 269/565. Estimated time remaining: 1491.59 seconds.\n",
            "Processed frame 270/565. Estimated time remaining: 1490.58 seconds.\n",
            "Processed frame 271/565. Estimated time remaining: 1488.64 seconds.\n",
            "Processed frame 272/565. Estimated time remaining: 1487.86 seconds.\n",
            "Processed frame 273/565. Estimated time remaining: 1477.55 seconds.\n",
            "Processed frame 274/565. Estimated time remaining: 1475.70 seconds.\n",
            "Processed frame 275/565. Estimated time remaining: 1474.27 seconds.\n",
            "Processed frame 276/565. Estimated time remaining: 1464.07 seconds.\n",
            "Processed frame 277/565. Estimated time remaining: 1453.94 seconds.\n",
            "Processed frame 278/565. Estimated time remaining: 1443.89 seconds.\n",
            "Processed frame 279/565. Estimated time remaining: 1433.90 seconds.\n",
            "Processed frame 280/565. Estimated time remaining: 1423.97 seconds.\n",
            "Processed frame 281/565. Estimated time remaining: 1414.13 seconds.\n",
            "Processed frame 282/565. Estimated time remaining: 1404.37 seconds.\n",
            "Processed frame 283/565. Estimated time remaining: 1403.49 seconds.\n",
            "Processed frame 284/565. Estimated time remaining: 1401.62 seconds.\n",
            "Processed frame 285/565. Estimated time remaining: 1392.08 seconds.\n",
            "Processed frame 286/565. Estimated time remaining: 1382.54 seconds.\n",
            "Processed frame 287/565. Estimated time remaining: 1380.88 seconds.\n",
            "Processed frame 288/565. Estimated time remaining: 1371.34 seconds.\n",
            "Processed frame 289/565. Estimated time remaining: 1370.22 seconds.\n",
            "Processed frame 290/565. Estimated time remaining: 1367.90 seconds.\n",
            "Processed frame 291/565. Estimated time remaining: 1366.59 seconds.\n",
            "Processed frame 292/565. Estimated time remaining: 1357.11 seconds.\n",
            "Processed frame 293/565. Estimated time remaining: 1347.71 seconds.\n",
            "Processed frame 294/565. Estimated time remaining: 1338.35 seconds.\n",
            "Processed frame 295/565. Estimated time remaining: 1329.07 seconds.\n",
            "Processed frame 296/565. Estimated time remaining: 1327.84 seconds.\n",
            "Processed frame 297/565. Estimated time remaining: 1325.42 seconds.\n",
            "Processed frame 298/565. Estimated time remaining: 1316.22 seconds.\n",
            "Processed frame 299/565. Estimated time remaining: 1307.06 seconds.\n",
            "Processed frame 300/565. Estimated time remaining: 1298.00 seconds.\n",
            "Processed frame 301/565. Estimated time remaining: 1289.07 seconds.\n",
            "Processed frame 302/565. Estimated time remaining: 1280.24 seconds.\n",
            "Processed frame 303/565. Estimated time remaining: 1271.45 seconds.\n",
            "Processed frame 304/565. Estimated time remaining: 1262.73 seconds.\n",
            "Processed frame 305/565. Estimated time remaining: 1254.03 seconds.\n",
            "Processed frame 306/565. Estimated time remaining: 1245.38 seconds.\n",
            "Processed frame 307/565. Estimated time remaining: 1236.79 seconds.\n",
            "Processed frame 308/565. Estimated time remaining: 1228.26 seconds.\n",
            "Processed frame 309/565. Estimated time remaining: 1219.79 seconds.\n",
            "Processed frame 310/565. Estimated time remaining: 1211.40 seconds.\n",
            "Processed frame 311/565. Estimated time remaining: 1203.03 seconds.\n",
            "Processed frame 312/565. Estimated time remaining: 1194.62 seconds.\n",
            "Processed frame 313/565. Estimated time remaining: 1186.24 seconds.\n",
            "Processed frame 314/565. Estimated time remaining: 1177.92 seconds.\n",
            "Processed frame 315/565. Estimated time remaining: 1169.66 seconds.\n",
            "Processed frame 316/565. Estimated time remaining: 1161.45 seconds.\n",
            "Processed frame 317/565. Estimated time remaining: 1153.28 seconds.\n",
            "Processed frame 318/565. Estimated time remaining: 1145.18 seconds.\n",
            "Processed frame 319/565. Estimated time remaining: 1137.12 seconds.\n",
            "Processed frame 320/565. Estimated time remaining: 1129.13 seconds.\n",
            "Processed frame 321/565. Estimated time remaining: 1121.16 seconds.\n",
            "Processed frame 322/565. Estimated time remaining: 1113.25 seconds.\n",
            "Processed frame 323/565. Estimated time remaining: 1105.39 seconds.\n",
            "Processed frame 324/565. Estimated time remaining: 1097.58 seconds.\n",
            "Processed frame 325/565. Estimated time remaining: 1089.81 seconds.\n",
            "Processed frame 326/565. Estimated time remaining: 1082.09 seconds.\n",
            "Processed frame 327/565. Estimated time remaining: 1080.03 seconds.\n",
            "Processed frame 328/565. Estimated time remaining: 1078.42 seconds.\n",
            "Processed frame 329/565. Estimated time remaining: 1070.75 seconds.\n",
            "Processed frame 330/565. Estimated time remaining: 1063.12 seconds.\n",
            "Processed frame 331/565. Estimated time remaining: 1061.72 seconds.\n",
            "Processed frame 332/565. Estimated time remaining: 1054.15 seconds.\n",
            "Processed frame 333/565. Estimated time remaining: 1046.61 seconds.\n",
            "Processed frame 334/565. Estimated time remaining: 1044.31 seconds.\n",
            "Processed frame 335/565. Estimated time remaining: 1042.89 seconds.\n",
            "Processed frame 336/565. Estimated time remaining: 1041.37 seconds.\n",
            "Processed frame 337/565. Estimated time remaining: 1038.97 seconds.\n",
            "Processed frame 338/565. Estimated time remaining: 1031.49 seconds.\n",
            "Processed frame 339/565. Estimated time remaining: 1024.05 seconds.\n",
            "Processed frame 340/565. Estimated time remaining: 1016.67 seconds.\n",
            "Processed frame 341/565. Estimated time remaining: 1009.32 seconds.\n",
            "Processed frame 342/565. Estimated time remaining: 1002.02 seconds.\n",
            "Processed frame 343/565. Estimated time remaining: 994.75 seconds.\n",
            "Processed frame 344/565. Estimated time remaining: 987.53 seconds.\n",
            "Processed frame 345/565. Estimated time remaining: 980.37 seconds.\n",
            "Processed frame 346/565. Estimated time remaining: 973.30 seconds.\n",
            "Processed frame 347/565. Estimated time remaining: 966.27 seconds.\n",
            "Processed frame 348/565. Estimated time remaining: 959.27 seconds.\n",
            "Processed frame 349/565. Estimated time remaining: 952.34 seconds.\n",
            "Processed frame 350/565. Estimated time remaining: 945.45 seconds.\n",
            "Processed frame 351/565. Estimated time remaining: 938.59 seconds.\n",
            "Processed frame 352/565. Estimated time remaining: 931.74 seconds.\n",
            "Processed frame 353/565. Estimated time remaining: 924.94 seconds.\n",
            "Processed frame 354/565. Estimated time remaining: 918.21 seconds.\n",
            "Processed frame 355/565. Estimated time remaining: 911.49 seconds.\n",
            "Processed frame 356/565. Estimated time remaining: 904.74 seconds.\n",
            "Processed frame 357/565. Estimated time remaining: 898.02 seconds.\n",
            "Processed frame 358/565. Estimated time remaining: 891.33 seconds.\n",
            "Processed frame 359/565. Estimated time remaining: 884.68 seconds.\n",
            "Processed frame 360/565. Estimated time remaining: 878.06 seconds.\n",
            "Processed frame 361/565. Estimated time remaining: 871.48 seconds.\n",
            "Processed frame 362/565. Estimated time remaining: 864.93 seconds.\n",
            "Processed frame 363/565. Estimated time remaining: 858.42 seconds.\n",
            "Processed frame 364/565. Estimated time remaining: 851.94 seconds.\n",
            "Processed frame 365/565. Estimated time remaining: 845.49 seconds.\n",
            "Processed frame 366/565. Estimated time remaining: 839.08 seconds.\n",
            "Processed frame 367/565. Estimated time remaining: 836.82 seconds.\n",
            "Processed frame 368/565. Estimated time remaining: 835.10 seconds.\n",
            "Processed frame 369/565. Estimated time remaining: 828.72 seconds.\n",
            "Processed frame 370/565. Estimated time remaining: 822.37 seconds.\n",
            "Processed frame 371/565. Estimated time remaining: 816.05 seconds.\n",
            "Processed frame 372/565. Estimated time remaining: 809.77 seconds.\n",
            "Processed frame 373/565. Estimated time remaining: 808.08 seconds.\n",
            "Processed frame 374/565. Estimated time remaining: 801.82 seconds.\n",
            "Processed frame 375/565. Estimated time remaining: 795.59 seconds.\n",
            "Processed frame 376/565. Estimated time remaining: 789.40 seconds.\n",
            "Processed frame 377/565. Estimated time remaining: 783.24 seconds.\n",
            "Processed frame 378/565. Estimated time remaining: 777.10 seconds.\n",
            "Processed frame 379/565. Estimated time remaining: 771.00 seconds.\n",
            "Processed frame 380/565. Estimated time remaining: 764.94 seconds.\n",
            "Processed frame 381/565. Estimated time remaining: 758.90 seconds.\n",
            "Processed frame 382/565. Estimated time remaining: 752.90 seconds.\n",
            "Processed frame 383/565. Estimated time remaining: 746.92 seconds.\n",
            "Processed frame 384/565. Estimated time remaining: 740.98 seconds.\n",
            "Processed frame 385/565. Estimated time remaining: 735.06 seconds.\n",
            "Processed frame 386/565. Estimated time remaining: 729.17 seconds.\n",
            "Processed frame 387/565. Estimated time remaining: 723.31 seconds.\n",
            "Processed frame 388/565. Estimated time remaining: 717.48 seconds.\n",
            "Processed frame 389/565. Estimated time remaining: 711.67 seconds.\n",
            "Processed frame 390/565. Estimated time remaining: 705.90 seconds.\n",
            "Processed frame 391/565. Estimated time remaining: 700.16 seconds.\n",
            "Processed frame 392/565. Estimated time remaining: 694.44 seconds.\n",
            "Processed frame 393/565. Estimated time remaining: 688.75 seconds.\n",
            "Processed frame 394/565. Estimated time remaining: 683.09 seconds.\n",
            "Processed frame 395/565. Estimated time remaining: 677.45 seconds.\n",
            "Processed frame 396/565. Estimated time remaining: 671.84 seconds.\n",
            "Processed frame 397/565. Estimated time remaining: 666.27 seconds.\n",
            "Processed frame 398/565. Estimated time remaining: 660.72 seconds.\n",
            "Processed frame 399/565. Estimated time remaining: 655.19 seconds.\n",
            "Processed frame 400/565. Estimated time remaining: 649.68 seconds.\n",
            "Processed frame 401/565. Estimated time remaining: 644.21 seconds.\n",
            "Processed frame 402/565. Estimated time remaining: 638.75 seconds.\n",
            "Processed frame 403/565. Estimated time remaining: 633.33 seconds.\n",
            "Processed frame 404/565. Estimated time remaining: 627.93 seconds.\n",
            "Processed frame 405/565. Estimated time remaining: 622.55 seconds.\n",
            "Processed frame 406/565. Estimated time remaining: 617.20 seconds.\n",
            "Processed frame 407/565. Estimated time remaining: 611.87 seconds.\n",
            "Processed frame 408/565. Estimated time remaining: 606.57 seconds.\n",
            "Processed frame 409/565. Estimated time remaining: 601.29 seconds.\n",
            "Processed frame 410/565. Estimated time remaining: 596.04 seconds.\n",
            "Processed frame 411/565. Estimated time remaining: 590.82 seconds.\n",
            "Processed frame 412/565. Estimated time remaining: 585.62 seconds.\n",
            "Processed frame 413/565. Estimated time remaining: 580.44 seconds.\n",
            "Processed frame 414/565. Estimated time remaining: 575.28 seconds.\n",
            "Processed frame 415/565. Estimated time remaining: 570.15 seconds.\n",
            "Processed frame 416/565. Estimated time remaining: 565.04 seconds.\n",
            "Processed frame 417/565. Estimated time remaining: 559.96 seconds.\n",
            "Processed frame 418/565. Estimated time remaining: 554.91 seconds.\n",
            "Processed frame 419/565. Estimated time remaining: 549.88 seconds.\n",
            "Processed frame 420/565. Estimated time remaining: 544.90 seconds.\n",
            "Processed frame 421/565. Estimated time remaining: 539.95 seconds.\n",
            "Processed frame 422/565. Estimated time remaining: 535.02 seconds.\n",
            "Processed frame 423/565. Estimated time remaining: 532.93 seconds.\n",
            "Processed frame 424/565. Estimated time remaining: 530.90 seconds.\n",
            "Processed frame 425/565. Estimated time remaining: 528.43 seconds.\n",
            "Processed frame 426/565. Estimated time remaining: 526.34 seconds.\n",
            "Processed frame 427/565. Estimated time remaining: 521.39 seconds.\n",
            "Processed frame 428/565. Estimated time remaining: 516.46 seconds.\n",
            "Processed frame 429/565. Estimated time remaining: 511.55 seconds.\n",
            "Processed frame 430/565. Estimated time remaining: 506.66 seconds.\n",
            "Processed frame 431/565. Estimated time remaining: 501.79 seconds.\n",
            "Processed frame 432/565. Estimated time remaining: 496.95 seconds.\n",
            "Processed frame 433/565. Estimated time remaining: 492.13 seconds.\n",
            "Processed frame 434/565. Estimated time remaining: 487.33 seconds.\n",
            "Processed frame 435/565. Estimated time remaining: 482.55 seconds.\n",
            "Processed frame 436/565. Estimated time remaining: 477.79 seconds.\n",
            "Processed frame 437/565. Estimated time remaining: 473.05 seconds.\n",
            "Processed frame 438/565. Estimated time remaining: 468.34 seconds.\n",
            "Processed frame 439/565. Estimated time remaining: 463.64 seconds.\n",
            "Processed frame 440/565. Estimated time remaining: 458.97 seconds.\n",
            "Processed frame 441/565. Estimated time remaining: 454.32 seconds.\n",
            "Processed frame 442/565. Estimated time remaining: 449.69 seconds.\n",
            "Processed frame 443/565. Estimated time remaining: 445.08 seconds.\n",
            "Processed frame 444/565. Estimated time remaining: 440.49 seconds.\n",
            "Processed frame 445/565. Estimated time remaining: 435.92 seconds.\n",
            "Processed frame 446/565. Estimated time remaining: 431.37 seconds.\n",
            "Processed frame 447/565. Estimated time remaining: 426.84 seconds.\n",
            "Processed frame 448/565. Estimated time remaining: 422.33 seconds.\n",
            "Processed frame 449/565. Estimated time remaining: 417.84 seconds.\n",
            "Processed frame 450/565. Estimated time remaining: 413.38 seconds.\n",
            "Processed frame 451/565. Estimated time remaining: 408.92 seconds.\n",
            "Processed frame 452/565. Estimated time remaining: 404.49 seconds.\n",
            "Processed frame 453/565. Estimated time remaining: 402.26 seconds.\n",
            "Processed frame 454/565. Estimated time remaining: 399.96 seconds.\n",
            "Processed frame 455/565. Estimated time remaining: 397.36 seconds.\n",
            "Processed frame 456/565. Estimated time remaining: 392.93 seconds.\n",
            "Processed frame 457/565. Estimated time remaining: 388.52 seconds.\n",
            "Processed frame 458/565. Estimated time remaining: 384.13 seconds.\n",
            "Processed frame 459/565. Estimated time remaining: 379.77 seconds.\n",
            "Processed frame 460/565. Estimated time remaining: 375.41 seconds.\n",
            "Processed frame 461/565. Estimated time remaining: 371.08 seconds.\n",
            "Processed frame 462/565. Estimated time remaining: 366.76 seconds.\n",
            "Processed frame 463/565. Estimated time remaining: 362.46 seconds.\n",
            "Processed frame 464/565. Estimated time remaining: 358.18 seconds.\n",
            "Processed frame 465/565. Estimated time remaining: 353.91 seconds.\n",
            "Processed frame 466/565. Estimated time remaining: 349.67 seconds.\n",
            "Processed frame 467/565. Estimated time remaining: 345.46 seconds.\n",
            "Processed frame 468/565. Estimated time remaining: 341.28 seconds.\n",
            "Processed frame 469/565. Estimated time remaining: 337.12 seconds.\n",
            "Processed frame 470/565. Estimated time remaining: 332.97 seconds.\n",
            "Processed frame 471/565. Estimated time remaining: 328.84 seconds.\n",
            "Processed frame 472/565. Estimated time remaining: 324.71 seconds.\n",
            "Processed frame 473/565. Estimated time remaining: 320.60 seconds.\n",
            "Processed frame 474/565. Estimated time remaining: 316.51 seconds.\n",
            "Processed frame 475/565. Estimated time remaining: 312.44 seconds.\n",
            "Processed frame 476/565. Estimated time remaining: 308.39 seconds.\n",
            "Processed frame 477/565. Estimated time remaining: 304.32 seconds.\n",
            "Processed frame 478/565. Estimated time remaining: 300.27 seconds.\n",
            "Processed frame 479/565. Estimated time remaining: 296.24 seconds.\n",
            "Processed frame 480/565. Estimated time remaining: 292.22 seconds.\n",
            "Processed frame 481/565. Estimated time remaining: 288.22 seconds.\n",
            "Processed frame 482/565. Estimated time remaining: 284.23 seconds.\n",
            "Processed frame 483/565. Estimated time remaining: 280.26 seconds.\n",
            "Processed frame 484/565. Estimated time remaining: 276.30 seconds.\n",
            "Processed frame 485/565. Estimated time remaining: 272.36 seconds.\n",
            "Processed frame 486/565. Estimated time remaining: 268.43 seconds.\n",
            "Processed frame 487/565. Estimated time remaining: 264.52 seconds.\n",
            "Processed frame 488/565. Estimated time remaining: 260.63 seconds.\n",
            "Processed frame 489/565. Estimated time remaining: 256.75 seconds.\n",
            "Processed frame 490/565. Estimated time remaining: 252.88 seconds.\n",
            "Processed frame 491/565. Estimated time remaining: 249.03 seconds.\n",
            "Processed frame 492/565. Estimated time remaining: 245.20 seconds.\n",
            "Processed frame 493/565. Estimated time remaining: 241.38 seconds.\n",
            "Processed frame 494/565. Estimated time remaining: 237.57 seconds.\n",
            "Processed frame 495/565. Estimated time remaining: 234.93 seconds.\n",
            "Processed frame 496/565. Estimated time remaining: 231.15 seconds.\n",
            "Processed frame 497/565. Estimated time remaining: 227.39 seconds.\n",
            "Processed frame 498/565. Estimated time remaining: 223.64 seconds.\n",
            "Processed frame 499/565. Estimated time remaining: 220.92 seconds.\n",
            "Processed frame 500/565. Estimated time remaining: 217.17 seconds.\n",
            "Processed frame 501/565. Estimated time remaining: 214.55 seconds.\n",
            "Processed frame 502/565. Estimated time remaining: 211.79 seconds.\n",
            "Processed frame 503/565. Estimated time remaining: 209.07 seconds.\n",
            "Processed frame 504/565. Estimated time remaining: 205.31 seconds.\n",
            "Processed frame 505/565. Estimated time remaining: 201.57 seconds.\n",
            "Processed frame 506/565. Estimated time remaining: 197.85 seconds.\n",
            "Processed frame 507/565. Estimated time remaining: 194.13 seconds.\n",
            "Processed frame 508/565. Estimated time remaining: 190.43 seconds.\n",
            "Processed frame 509/565. Estimated time remaining: 186.75 seconds.\n",
            "Processed frame 510/565. Estimated time remaining: 183.08 seconds.\n",
            "Processed frame 511/565. Estimated time remaining: 179.42 seconds.\n",
            "Processed frame 512/565. Estimated time remaining: 175.77 seconds.\n",
            "Processed frame 513/565. Estimated time remaining: 172.14 seconds.\n",
            "Processed frame 514/565. Estimated time remaining: 168.52 seconds.\n",
            "Processed frame 515/565. Estimated time remaining: 164.92 seconds.\n",
            "Processed frame 516/565. Estimated time remaining: 161.33 seconds.\n",
            "Processed frame 517/565. Estimated time remaining: 157.75 seconds.\n",
            "Processed frame 518/565. Estimated time remaining: 154.18 seconds.\n",
            "Processed frame 519/565. Estimated time remaining: 150.62 seconds.\n",
            "Processed frame 520/565. Estimated time remaining: 147.08 seconds.\n",
            "Processed frame 521/565. Estimated time remaining: 143.56 seconds.\n",
            "Processed frame 522/565. Estimated time remaining: 140.05 seconds.\n",
            "Processed frame 523/565. Estimated time remaining: 136.56 seconds.\n",
            "Processed frame 524/565. Estimated time remaining: 133.08 seconds.\n",
            "Processed frame 525/565. Estimated time remaining: 129.61 seconds.\n",
            "Processed frame 526/565. Estimated time remaining: 126.15 seconds.\n",
            "Processed frame 527/565. Estimated time remaining: 122.70 seconds.\n",
            "Processed frame 528/565. Estimated time remaining: 119.27 seconds.\n",
            "Processed frame 529/565. Estimated time remaining: 115.84 seconds.\n",
            "Processed frame 530/565. Estimated time remaining: 112.43 seconds.\n",
            "Processed frame 531/565. Estimated time remaining: 109.03 seconds.\n",
            "Processed frame 532/565. Estimated time remaining: 105.64 seconds.\n",
            "Processed frame 533/565. Estimated time remaining: 102.27 seconds.\n",
            "Processed frame 534/565. Estimated time remaining: 98.89 seconds.\n",
            "Processed frame 535/565. Estimated time remaining: 95.53 seconds.\n",
            "Processed frame 536/565. Estimated time remaining: 92.19 seconds.\n",
            "Processed frame 537/565. Estimated time remaining: 88.85 seconds.\n",
            "Processed frame 538/565. Estimated time remaining: 85.52 seconds.\n",
            "Processed frame 539/565. Estimated time remaining: 82.21 seconds.\n",
            "Processed frame 540/565. Estimated time remaining: 78.91 seconds.\n",
            "Processed frame 541/565. Estimated time remaining: 75.62 seconds.\n",
            "Processed frame 542/565. Estimated time remaining: 72.34 seconds.\n",
            "Processed frame 543/565. Estimated time remaining: 69.07 seconds.\n",
            "Processed frame 544/565. Estimated time remaining: 65.81 seconds.\n",
            "Processed frame 545/565. Estimated time remaining: 62.57 seconds.\n",
            "Processed frame 546/565. Estimated time remaining: 59.34 seconds.\n",
            "Processed frame 547/565. Estimated time remaining: 56.11 seconds.\n",
            "Processed frame 548/565. Estimated time remaining: 52.90 seconds.\n",
            "Processed frame 549/565. Estimated time remaining: 49.70 seconds.\n",
            "Processed frame 550/565. Estimated time remaining: 46.52 seconds.\n",
            "Processed frame 551/565. Estimated time remaining: 43.34 seconds.\n",
            "Processed frame 552/565. Estimated time remaining: 40.17 seconds.\n",
            "Processed frame 553/565. Estimated time remaining: 37.02 seconds.\n",
            "Processed frame 554/565. Estimated time remaining: 33.87 seconds.\n",
            "Processed frame 555/565. Estimated time remaining: 30.74 seconds.\n",
            "Processed frame 556/565. Estimated time remaining: 27.62 seconds.\n",
            "Processed frame 557/565. Estimated time remaining: 24.51 seconds.\n",
            "Processed frame 558/565. Estimated time remaining: 21.41 seconds.\n",
            "Processed frame 559/565. Estimated time remaining: 18.32 seconds.\n",
            "Processed frame 560/565. Estimated time remaining: 15.24 seconds.\n",
            "Processed frame 561/565. Estimated time remaining: 12.17 seconds.\n",
            "Processed frame 562/565. Estimated time remaining: 9.11 seconds.\n",
            "Processed frame 563/565. Estimated time remaining: 6.06 seconds.\n",
            "Processed frame 564/565. Estimated time remaining: 3.03 seconds.\n",
            "Processed frame 565/565. Estimated time remaining: 0.00 seconds.\n",
            "Transformed video saved at: output_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1' -O /content/AnimeGANv3_Hayao_STYLE_36.onnx\n",
        "!pip install onnxruntime\n",
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4YPU3Vf_KqQ",
        "outputId": "b7109834-6f19-4147-f11e-c17b4f6a4a0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-08 12:57:13--  https://docs.google.com/uc?export=download&id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.2.102, 142.251.2.100, 142.251.2.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.2.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1&export=download [following]\n",
            "--2024-11-08 12:57:13--  https://drive.usercontent.google.com/download?id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.137.132, 2607:f8b0:4023:c03::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.137.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4232991 (4.0M) [application/octet-stream]\n",
            "Saving to: ‘/content/AnimeGANv3_Hayao_STYLE_36.onnx’\n",
            "\n",
            "/content/AnimeGANv3 100%[===================>]   4.04M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-11-08 12:57:17 (28.4 MB/s) - ‘/content/AnimeGANv3_Hayao_STYLE_36.onnx’ saved [4232991/4232991]\n",
            "\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.20.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, huggingface-hub, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.4 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 huggingface-hub-0.26.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.3 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to process the video and generate anime style output\n",
        "def process_video(input_video):\n",
        "    cap = cv2.VideoCapture(input_video)\n",
        "    anime_frames = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        # Apply your anime transformation here\n",
        "        anime_frame = apply_anime_style(frame)  # Replace with your actual function\n",
        "        anime_frames.append(anime_frame)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    output_video = \"output_anime_video.mp4\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video, fourcc, 30.0, (anime_frames[0].shape[1], anime_frames[0].shape[0]))\n",
        "\n",
        "    for frame in anime_frames:\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "    return output_video\n",
        "\n",
        "# Function to evaluate the animeness of the video\n",
        "def evaluate_animeness(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    score = 0\n",
        "    num_frames = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        num_frames += 1\n",
        "        score += analyze_frame_for_animeness(frame)  # Replace with your actual analysis function\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if num_frames > 0:\n",
        "        score /= num_frames\n",
        "\n",
        "    return score\n",
        "\n",
        "# Gradio interface function\n",
        "def generate_anime_video(input_video):\n",
        "    anime_video = process_video(input_video)\n",
        "    animeness_score = evaluate_animeness(input_video)\n",
        "    return anime_video, f\"Animeness Score: {animeness_score:.2f}\"\n",
        "\n",
        "# Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_anime_video,\n",
        "    inputs=gr.Video(label=\"Input Video\"),\n",
        "    outputs=[gr.Video(label=\"Anime Video\"), gr.Textbox(label=\"Animeness Score\")],\n",
        "    title=\"Anime Video Generation with Evaluation\",\n",
        "    description=\"Convert a normal video into anime style and evaluate its animeness.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "id": "db6kYM2wRLEc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "6aa9f1ba-b1ad-4890-adf2-c9f05c54365a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3ca30adff9c14d430c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3ca30adff9c14d430c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1' -O /kaggle/working/AnimeGANv3_Hayao_STYLE_36.onnx\n",
        "!pip install gradio\n",
        "!pip install onnxruntime\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1' -O /content/AnimeGANv3_Hayao_STYLE_36.onnx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQNvOZErsSb3",
        "outputId": "b23f47de-1c52-4228-9f73-9f9285c6fb2a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.5.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.4)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.4.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.4.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart==0.0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.3)\n",
            "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.2)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.20.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "--2024-11-08 14:10:35--  https://docs.google.com/uc?export=download&id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.2.113, 142.251.2.138, 142.251.2.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.2.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1&export=download [following]\n",
            "--2024-11-08 14:10:35--  https://drive.usercontent.google.com/download?id=1ud-QxEtdp4bMODFUMHCZluy2Ic0Yfns1&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.2.132, 2607:f8b0:4023:c03::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4232991 (4.0M) [application/octet-stream]\n",
            "Saving to: ‘/content/AnimeGANv3_Hayao_STYLE_36.onnx’\n",
            "\n",
            "/content/AnimeGANv3 100%[===================>]   4.04M  26.5MB/s    in 0.2s    \n",
            "\n",
            "2024-11-08 14:10:39 (26.5 MB/s) - ‘/content/AnimeGANv3_Hayao_STYLE_36.onnx’ saved [4232991/4232991]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LLAwMZQC_ISJ",
        "outputId": "065372a5-6663-4675-fe9e-93701e3902af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.20.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.4)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.4.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.4.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart==0.0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.2)\n",
            "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.2)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:115: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "Using cache found in /root/.cache/torch/hub/bryandlee_animegan2-pytorch_main\n",
            "Using cache found in /root/.cache/torch/hub/bryandlee_animegan2-pytorch_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1adfc208d79e8a0d1a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1adfc208d79e8a0d1a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Need \u001b[32m'write'\u001b[0m access token to create a Spaces repo.\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "Enter your token (input will not be visible): "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iE4_wyHCy5om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zwqwEcI5x6Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import onnxruntime as ort\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import json\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "\n",
        "# Load the AnimeGANv3 model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = 'AnimeGANv3_Hayao_STYLE_36'  # Model name\n",
        "session = ort.InferenceSession(f'/content/{model}.onnx', providers=['CUDAExecutionProvider' if device == 'cuda' else 'CPUExecutionProvider'])\n",
        "\n",
        "# Load the face2paint model\n",
        "face2paint_model = torch.hub.load(\"bryandlee/animegan2-pytorch:main\", \"generator\", device=device).eval()\n",
        "face2paint = torch.hub.load(\"bryandlee/animegan2-pytorch:main\", \"face2paint\", device=device)\n",
        "\n",
        "# Function to preprocess image for AnimeGANv3\n",
        "def process_image(img):\n",
        "    img = cv2.resize(img, (512, 512))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 127.5 - 1.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Function to convert non-face areas using AnimeGANv3\n",
        "def convert_non_face(img, original_shape):\n",
        "    x = session.get_inputs()[0].name\n",
        "    fake_img = session.run(None, {x: img})[0]\n",
        "    images = (np.squeeze(fake_img) + 1.) / 2 * 255\n",
        "    images = np.clip(images, 0, 255).astype(np.uint8)\n",
        "    output_image = cv2.resize(images, (original_shape[1], original_shape[0]))\n",
        "    return cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Function to extract face using OpenCV's Haar Cascade\n",
        "def extract_face(image):\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    img_array = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face = img_array[y:y+h, x:x+w]\n",
        "        return face, (x, y, w, h)\n",
        "    return None, None\n",
        "\n",
        "# Function to calculate edge density\n",
        "def calculate_edge_density(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray_image, 100, 200)\n",
        "    return np.sum(edges) / (image.shape[0] * image.shape[1])\n",
        "\n",
        "# Function to calculate color metrics\n",
        "def calculate_color_metrics(image):\n",
        "    mean_color = np.mean(image, axis=(0, 1))\n",
        "    std_dev_color = np.std(image, axis=(0, 1))\n",
        "    return mean_color, std_dev_color\n",
        "\n",
        "# Function to calculate texture metrics using GLCM\n",
        "def calculate_texture_metrics(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    glcm = graycomatrix(gray_image, distances=[1], angles=[0], symmetric=True, normed=True)\n",
        "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
        "    correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
        "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
        "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
        "    total_variation = np.sum(np.abs(np.diff(gray_image, axis=0))) + np.sum(np.abs(np.diff(gray_image, axis=1)))\n",
        "\n",
        "    return contrast, correlation, energy, homogeneity, total_variation\n",
        "\n",
        "# Function to process video and analyze metrics\n",
        "def process_and_analyze_video(video_file):\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Video Writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter('/content/output_video.avi', fourcc, fps, (width, height))\n",
        "\n",
        "    # Variables to store metrics\n",
        "    frame_metrics = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        face, coords = extract_face(frame)\n",
        "\n",
        "        if face is not None:\n",
        "            face_pil = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
        "            im_out = face2paint(face2paint_model, face_pil, side_by_side=False)\n",
        "            im_out_np = np.array(im_out)\n",
        "            resized_face = cv2.resize(im_out_np, (coords[2], coords[3]))\n",
        "            frame[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]] = resized_face\n",
        "\n",
        "        full_transformed_img = convert_non_face(process_image(frame), frame.shape)\n",
        "\n",
        "        # Mask for non-face areas\n",
        "        mask = np.ones(frame.shape[:2], dtype=np.uint8) * 255\n",
        "        if face is not None:\n",
        "            mask[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]] = 0\n",
        "        frame[mask == 255] = full_transformed_img[mask == 255]\n",
        "\n",
        "        # Collect metrics for animeness score\n",
        "        edge_density = calculate_edge_density(frame)\n",
        "        mean_color, std_dev_color = calculate_color_metrics(frame)\n",
        "        contrast, correlation, energy, homogeneity, total_variation = calculate_texture_metrics(frame)\n",
        "\n",
        "        frame_metrics.append({\n",
        "            'Mean Color': mean_color,\n",
        "            'Standard Deviation of Color': std_dev_color,\n",
        "            'Edge Density': edge_density,\n",
        "            'Total Variation': total_variation,\n",
        "            'Contrast': contrast,\n",
        "            'Correlation': correlation,\n",
        "            'Energy': energy,\n",
        "            'Homogeneity': homogeneity\n",
        "        })\n",
        "\n",
        "        # Write processed frame to output\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # Average metrics\n",
        "    metrics_average = {\n",
        "        'Mean Color': np.mean([metric['Mean Color'] for metric in frame_metrics], axis=0),\n",
        "        'Standard Deviation of Color': np.mean([metric['Standard Deviation of Color'] for metric in frame_metrics], axis=0),\n",
        "        'Edge Density': np.mean([metric['Edge Density'] for metric in frame_metrics]),\n",
        "        'Total Variation': np.mean([metric['Total Variation'] for metric in frame_metrics]),\n",
        "        'Contrast': np.mean([metric['Contrast'] for metric in frame_metrics]),\n",
        "        'Correlation': np.mean([metric['Correlation'] for metric in frame_metrics]),\n",
        "        'Energy': np.mean([metric['Energy'] for metric in frame_metrics]),\n",
        "        'Homogeneity': np.mean([metric['Homogeneity'] for metric in frame_metrics])\n",
        "    }\n",
        "\n",
        "    return '/content/output_video.avi', metrics_average\n",
        "\n",
        "# Function to load histogram data from JSON file\n",
        "def load_histogram_data(json_file):\n",
        "    with open(json_file, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "# Function to calculate animeness score\n",
        "def calculate_anime_metrics(video_metrics, folder_metrics):\n",
        "    # Here you can define weights for each metric based on their importance\n",
        "    weights = {\n",
        "        'Mean Color': 0.15,\n",
        "        'Standard Deviation of Color': 0.15,\n",
        "        'Edge Density': 0.1,\n",
        "        'Total Variation': 0.1,\n",
        "        'Contrast': 0.15,\n",
        "        'Correlation': 0.1,\n",
        "        'Energy': 0.15,\n",
        "        'Homogeneity': 0.1\n",
        "    }\n",
        "\n",
        "    # Calculate the animeness score\n",
        "    animeness_score = 0\n",
        "    for metric in weights.keys():\n",
        "        # Normalize metrics from video and folder metrics to the same scale (0-1)\n",
        "        video_value = video_metrics[metric]\n",
        "        folder_value = folder_metrics.get(metric, np.mean(video_metrics[metric]))  # Default to mean if not found\n",
        "        animeness_score += weights[metric] * ((video_value + folder_value) / 2)\n",
        "\n",
        "    return animeness_score\n",
        "\n",
        "# Gradio Interface\n",
        "def gradio_interface(video):\n",
        "    # Process the input video and get the transformed output and metrics\n",
        "    transformed_video, video_metrics = process_and_analyze_video(video)\n",
        "\n",
        "    # Load original metrics from JSON\n",
        "    json_file = 'mean_metrics.json'  # Replace with your actual histogram JSON file\n",
        "    original_metrics = load_histogram_data(json_file)\n",
        "\n",
        "    # Calculate animeness score\n",
        "    animeness_score = calculate_anime_metrics(video_metrics, original_metrics)\n",
        "\n",
        "    return video, transformed_video, {'Video Metrics': video_metrics, 'Original Metrics': original_metrics, 'Animeness Score': animeness_score}\n",
        "\n",
        "# Launch Gradio app\n",
        "gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs='file',\n",
        "    outputs=[gr.Video(label=\"Original Video\"), gr.Video(label=\"Transformed Video\"), gr.JSON(label=\"Metrics\")],\n",
        "    title=\"Anime Video Transformation\",\n",
        "    description=\"Upload a video to transform it into an anime style and analyze its metrics.\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "z1Nzv4jhBSzk",
        "outputId": "8a2805cd-bd1d-4fe1-92fa-8346a8cb5361"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:115: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "Using cache found in /root/.cache/torch/hub/bryandlee_animegan2-pytorch_main\n",
            "Using cache found in /root/.cache/torch/hub/bryandlee_animegan2-pytorch_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://288f6acae236c84879.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://288f6acae236c84879.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import onnxruntime as ort\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import json\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "import os\n",
        "import math\n",
        "# Load the AnimeGANv3 model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = 'AnimeGANv3_Hayao_STYLE_36'\n",
        "session = ort.InferenceSession(f'/content/{model}.onnx', providers=['CUDAExecutionProvider' if device == 'cuda' else 'CPUExecutionProvider'])\n",
        "\n",
        "# Load the face2paint model\n",
        "face2paint_model = torch.hub.load(\"bryandlee/animegan2-pytorch:main\", \"generator\", device=device).eval()\n",
        "face2paint = torch.hub.load(\"bryandlee/animegan2-pytorch:main\", \"face2paint\", device=device)\n",
        "\n",
        "# Function to preprocess image for AnimeGANv3\n",
        "def process_image(img):\n",
        "    img = cv2.resize(img, (512, 512))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 127.5 - 1.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Function to convert non-face areas using AnimeGANv3\n",
        "def convert_non_face(img, original_shape):\n",
        "    x = session.get_inputs()[0].name\n",
        "    fake_img = session.run(None, {x: img})[0]\n",
        "    images = (np.squeeze(fake_img) + 1.) / 2 * 255\n",
        "    images = np.clip(images, 0, 255).astype(np.uint8)\n",
        "    output_image = cv2.resize(images, (original_shape[1], original_shape[0]))\n",
        "    return cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Function to extract face using OpenCV's Haar Cascade\n",
        "def extract_face(image):\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    img_array = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face = img_array[y:y+h, x:x+w]\n",
        "        return face, (x, y, w, h)\n",
        "    return None, None\n",
        "\n",
        "# Function to calculate edge density\n",
        "def calculate_edge_density(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray_image, 100, 200)\n",
        "    return np.sum(edges) / (image.shape[0] * image.shape[1])\n",
        "\n",
        "# Function to calculate color metrics\n",
        "def calculate_color_metrics(image):\n",
        "    mean_color = np.mean(image, axis=(0, 1))\n",
        "    std_dev_color = np.std(image, axis=(0, 1))\n",
        "    return mean_color, std_dev_color\n",
        "\n",
        "# Function to calculate texture metrics using GLCM\n",
        "def calculate_texture_metrics(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    glcm = graycomatrix(gray_image, distances=[1], angles=[0], symmetric=True, normed=True)\n",
        "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
        "    correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
        "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
        "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
        "    total_variation = np.sum(np.abs(np.diff(gray_image, axis=0))) + np.sum(np.abs(np.diff(gray_image, axis=1)))\n",
        "\n",
        "    return contrast, correlation, energy, homogeneity, total_variation\n",
        "\n",
        "# Process and analyze video\n",
        "def process_and_analyze_video(video_file):\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    out_path = '/content/output_video.avi'\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_metrics = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        face, coords = extract_face(frame)\n",
        "\n",
        "        if face is not None:\n",
        "            face_pil = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
        "            im_out = face2paint(face2paint_model, face_pil, side_by_side=False)\n",
        "            im_out_np = np.array(im_out)\n",
        "            resized_face = cv2.resize(im_out_np, (coords[2], coords[3]))\n",
        "            frame[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]] = resized_face\n",
        "\n",
        "        full_transformed_img = convert_non_face(process_image(frame), frame.shape)\n",
        "\n",
        "        mask = np.ones(frame.shape[:2], dtype=np.uint8) * 255\n",
        "        if face is not None:\n",
        "            mask[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]] = 0\n",
        "        frame[mask == 255] = full_transformed_img[mask == 255]\n",
        "\n",
        "        edge_density = calculate_edge_density(frame)\n",
        "        mean_color, std_dev_color = calculate_color_metrics(frame)\n",
        "        contrast, correlation, energy, homogeneity, total_variation = calculate_texture_metrics(frame)\n",
        "\n",
        "        frame_metrics.append({\n",
        "            'Mean Color': mean_color,\n",
        "            'Standard Deviation of Color': std_dev_color,\n",
        "            'Edge Density': edge_density,\n",
        "            'Total Variation': total_variation,\n",
        "            'Contrast': contrast,\n",
        "            'Correlation': correlation,\n",
        "            'Energy': energy,\n",
        "            'Homogeneity': homogeneity\n",
        "        })\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    metrics_average = {\n",
        "        'Mean Color': np.mean([metric['Mean Color'] for metric in frame_metrics], axis=0),\n",
        "        'Standard Deviation of Color': np.mean([metric['Standard Deviation of Color'] for metric in frame_metrics], axis=0),\n",
        "        'Edge Density': np.mean([metric['Edge Density'] for metric in frame_metrics]),\n",
        "        'Total Variation': np.mean([metric['Total Variation'] for metric in frame_metrics]),\n",
        "        'Contrast': np.mean([metric['Contrast'] for metric in frame_metrics]),\n",
        "        'Correlation': np.mean([metric['Correlation'] for metric in frame_metrics]),\n",
        "        'Energy': np.mean([metric['Energy'] for metric in frame_metrics]),\n",
        "        'Homogeneity': np.mean([metric['Homogeneity'] for metric in frame_metrics])\n",
        "    }\n",
        "\n",
        "    return out_path, metrics_average\n",
        "\n",
        "def load_histogram_data(json_file):\n",
        "    with open(json_file, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "def calculate_anime_metrics(video_metrics, folder_metrics):\n",
        "    weights = {\n",
        "        'Mean Color': 0,\n",
        "        'Standard Deviation of Color': 0,\n",
        "        'Edge Density': 0.25,\n",
        "        'Total Variation': 0.0,\n",
        "        'Contrast': 0.15,\n",
        "        'Correlation': 0.2,\n",
        "        'Energy': 0.2,\n",
        "        'Homogeneity': 0.2\n",
        "    }\n",
        "\n",
        "    animeness_score = 0\n",
        "    for metric in weights.keys():\n",
        "        video_value = video_metrics[metric]\n",
        "        folder_value = folder_metrics.get(metric, np.mean(video_metrics[metric]))\n",
        "        animeness_score += weights[metric] * (abs((video_value - folder_value)))\n",
        "\n",
        "    return abs(2/(1+math.exp(-0.01*animeness_score[0])) - 2)\n",
        "\n",
        "def gradio_interface(video):\n",
        "    transformed_video, video_metrics = process_and_analyze_video(video)\n",
        "    json_file = 'mean_metrics.json'\n",
        "    original_metrics = load_histogram_data(json_file)\n",
        "    animeness_score = calculate_anime_metrics(video_metrics, original_metrics)\n",
        "\n",
        "    return video, transformed_video, {'Video Metrics': video_metrics, 'Original Metrics': original_metrics, 'Animeness Score': animeness_score}\n",
        "\n",
        "gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs='file',\n",
        "    outputs=[gr.Video(label=\"Original Video\"), gr.Video(label=\"Transformed Video\"), gr.JSON(label=\"Metrics\")],\n",
        "    title=\"Anime Video Transformation\",\n",
        "    description=\"Upload a video to transform it into an anime style and analyze its metrics.\"\n",
        ").launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "z5CFFdct-EYo",
        "outputId": "5ee39f56-408b-45cf-d614-ba31d22c84bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:115: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "Using cache found in /root/.cache/torch/hub/bryandlee_animegan2-pytorch_main\n",
            "Using cache found in /root/.cache/torch/hub/bryandlee_animegan2-pytorch_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8fc2c1057dae0568aa.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8fc2c1057dae0568aa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/video.py:337: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c11bd29632ee4282bcfde719c6ed4d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Upload Video to Transform",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3f2acbcc67354bc79bae93ae6e5d7a38",
            "style": "IPY_MODEL_45d9526b78c24d62988518aa5c571cf3",
            "tooltip": ""
          }
        },
        "3f2acbcc67354bc79bae93ae6e5d7a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d9526b78c24d62988518aa5c571cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "8e31dccc22a6446cb2eb73327de18226": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7cc3a88186444cb984cbb2ebbad5ceac",
            "msg_id": "",
            "outputs": []
          }
        },
        "7cc3a88186444cb984cbb2ebbad5ceac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}